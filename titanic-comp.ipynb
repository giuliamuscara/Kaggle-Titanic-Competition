{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d51336c",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-06-04T21:52:11.701750Z",
     "iopub.status.busy": "2023-06-04T21:52:11.701322Z",
     "iopub.status.idle": "2023-06-04T21:53:43.251533Z",
     "shell.execute_reply": "2023-06-04T21:53:43.250388Z"
    },
    "papermill": {
     "duration": 91.558639,
     "end_time": "2023-06-04T21:53:43.256113",
     "exception": false,
     "start_time": "2023-06-04T21:52:11.697474",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/titanic/train.csv\n",
      "/kaggle/input/titanic/test.csv\n",
      "/kaggle/input/titanic/gender_submission.csv\n",
      "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
      "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
      "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
      "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
      "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
      "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
      "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
      "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
      "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
      "\n",
      "            Parch        Fare  \n",
      "count  891.000000  891.000000  \n",
      "mean     0.381594   32.204208  \n",
      "std      0.806057   49.693429  \n",
      "min      0.000000    0.000000  \n",
      "25%      0.000000    7.910400  \n",
      "50%      0.000000   14.454200  \n",
      "75%      0.000000   31.000000  \n",
      "max      6.000000  512.329200  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_21/2863829748.py:39: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  samples.loc[samples['Name'].notnull(), 'NameLen'] = samples['Name'].str.len()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters are: {'max_depth': None, 'n_estimators': 250}\n",
      "\n",
      "\n",
      "0.703 + or -0.069 for the {'max_depth': 2, 'n_estimators': 5}\n",
      "0.691 + or -0.066 for the {'max_depth': 2, 'n_estimators': 10}\n",
      "0.691 + or -0.04 for the {'max_depth': 2, 'n_estimators': 50}\n",
      "0.675 + or -0.044 for the {'max_depth': 2, 'n_estimators': 100}\n",
      "0.662 + or -0.036 for the {'max_depth': 2, 'n_estimators': 250}\n",
      "0.73 + or -0.07 for the {'max_depth': 4, 'n_estimators': 5}\n",
      "0.791 + or -0.049 for the {'max_depth': 4, 'n_estimators': 10}\n",
      "0.778 + or -0.038 for the {'max_depth': 4, 'n_estimators': 50}\n",
      "0.787 + or -0.038 for the {'max_depth': 4, 'n_estimators': 100}\n",
      "0.787 + or -0.03 for the {'max_depth': 4, 'n_estimators': 250}\n",
      "0.79 + or -0.037 for the {'max_depth': 8, 'n_estimators': 5}\n",
      "0.799 + or -0.042 for the {'max_depth': 8, 'n_estimators': 10}\n",
      "0.811 + or -0.037 for the {'max_depth': 8, 'n_estimators': 50}\n",
      "0.811 + or -0.028 for the {'max_depth': 8, 'n_estimators': 100}\n",
      "0.811 + or -0.033 for the {'max_depth': 8, 'n_estimators': 250}\n",
      "0.819 + or -0.027 for the {'max_depth': 16, 'n_estimators': 5}\n",
      "0.815 + or -0.036 for the {'max_depth': 16, 'n_estimators': 10}\n",
      "0.828 + or -0.034 for the {'max_depth': 16, 'n_estimators': 50}\n",
      "0.831 + or -0.036 for the {'max_depth': 16, 'n_estimators': 100}\n",
      "0.827 + or -0.04 for the {'max_depth': 16, 'n_estimators': 250}\n",
      "0.819 + or -0.029 for the {'max_depth': 32, 'n_estimators': 5}\n",
      "0.835 + or -0.041 for the {'max_depth': 32, 'n_estimators': 10}\n",
      "0.828 + or -0.037 for the {'max_depth': 32, 'n_estimators': 50}\n",
      "0.838 + or -0.039 for the {'max_depth': 32, 'n_estimators': 100}\n",
      "0.838 + or -0.034 for the {'max_depth': 32, 'n_estimators': 250}\n",
      "0.822 + or -0.045 for the {'max_depth': None, 'n_estimators': 5}\n",
      "0.827 + or -0.039 for the {'max_depth': None, 'n_estimators': 10}\n",
      "0.833 + or -0.042 for the {'max_depth': None, 'n_estimators': 50}\n",
      "0.842 + or -0.034 for the {'max_depth': None, 'n_estimators': 100}\n",
      "0.843 + or -0.041 for the {'max_depth': None, 'n_estimators': 250}\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import os\n",
    "from xgboost import XGBClassifier\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "import csv \n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "np.random.seed(31415)\n",
    "test_file = pd.read_csv(\"/kaggle/input/titanic/test.csv\")\n",
    "#print(test_file.shape) #(418,11)\n",
    "\n",
    "train_file = pd.read_csv(\"/kaggle/input/titanic/train.csv\")\n",
    "#print(train_file.shape) #(891,12)\n",
    "print(train_file.describe())\n",
    "#print(train_file.columns)\n",
    "samples = train_file[['Pclass', 'Name','Sex', 'Age', 'SibSp',\n",
    "       'Parch', 'Ticket','Fare']] #excluding embarked and cabin, many nans and passID\n",
    "\n",
    "#Preparing data\n",
    "#print(samples['Age'].value_counts(dropna=False)) \n",
    "samples[\"Age\"].fillna(\n",
    "    samples.groupby([\"Sex\"])[\"Age\"].transform(\n",
    "        lambda x: x.mean()\n",
    "    ), inplace=True)\n",
    "#print(samples['Age'])\n",
    "\n",
    "samples.loc[samples['Name'].notnull(), 'NameLen'] = samples['Name'].str.len()\n",
    "\n",
    "count = 0\n",
    "for idx in samples['Name']: #turn name into title, more meaningful\n",
    "    idx = idx.split(\",\")[1].split(\".\")[0]\n",
    "    #print(idx)\n",
    "    samples.iloc[count,1] = idx\n",
    "    #print(samples.iloc[count,1])\n",
    "    count=count+1\n",
    "                  \n",
    "#samples.loc[samples['Cabin'].notnull(), 'Cabin'] = samples['Cabin'].str[0] #replace cabin with its initial letter\n",
    "#cond = (samples['Sex'] == female)\n",
    "#result_female_ages = samples[cond].column_3.values[0]\n",
    "\n",
    "#samples.loc[samples['Embarked'].isna(), 'Embarked'] = \"S\"\n",
    "#print(samples.iloc[:,:].head(10))\n",
    "\n",
    "samples = pd.get_dummies(samples, prefix=['Sex', 'Ticket','Name'],\n",
    "                         columns=['Sex','Ticket','Name']) #one-hot encoding\n",
    "samples = np.array(samples)\n",
    "\n",
    "labels = train_file[ 'Survived']\n",
    "#print(samples.shape, labels.shape)\n",
    "labels = np.array(labels)\n",
    "\n",
    "#train_features, test_features, train_labels, test_labels = train_test_split(samples, labels, test_size = 0.25, random_state = 42)\n",
    "\n",
    "#random forest classifier model\n",
    "clf = RandomForestClassifier()\n",
    "#xgb = XGBClassifier()\n",
    "\n",
    "parameters = {\n",
    "    \"n_estimators\":[5,10,50,100,250],\n",
    "    \"max_depth\":[2,4,8,16,32,None]\n",
    "}\n",
    "\n",
    "#grid search of best parameters and kfold cross validation\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "cv = GridSearchCV(clf,parameters,cv=10)\n",
    "cv.fit(samples,labels)\n",
    "\n",
    "\n",
    "def display(results):\n",
    "    print(f'Best parameters are: {results.best_params_}')\n",
    "    print(\"\\n\")\n",
    "    mean_score = results.cv_results_['mean_test_score']\n",
    "    std_score = results.cv_results_['std_test_score']\n",
    "    params = results.cv_results_['params']\n",
    "    for mean,std,params in zip(mean_score,std_score,params):\n",
    "        print(f'{round(mean,3)} + or -{round(std,3)} for the {params}')\n",
    "        \n",
    "display(cv)\n",
    "\n",
    "best_RF_model = RandomForestClassifier(n_estimators = 250)\n",
    "\n",
    "        \n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 105.312302,
   "end_time": "2023-06-04T21:53:44.282134",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-06-04T21:51:58.969832",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
