{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31f90502",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-11-06T14:14:56.064826Z",
     "iopub.status.busy": "2024-11-06T14:14:56.064348Z",
     "iopub.status.idle": "2024-11-06T14:16:11.295932Z",
     "shell.execute_reply": "2024-11-06T14:16:11.294690Z"
    },
    "papermill": {
     "duration": 75.239807,
     "end_time": "2024-11-06T14:16:11.299069",
     "exception": false,
     "start_time": "2024-11-06T14:14:56.059262",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/titanic/train.csv\n",
      "/kaggle/input/titanic/test.csv\n",
      "/kaggle/input/titanic/gender_submission.csv\n",
      "(418, 11)\n",
      "       PassengerId      Pclass         Age       SibSp       Parch        Fare\n",
      "count   418.000000  418.000000  332.000000  418.000000  418.000000  417.000000\n",
      "mean   1100.500000    2.265550   30.272590    0.447368    0.392344   35.627188\n",
      "std     120.810458    0.841838   14.181209    0.896760    0.981429   55.907576\n",
      "min     892.000000    1.000000    0.170000    0.000000    0.000000    0.000000\n",
      "25%     996.250000    1.000000   21.000000    0.000000    0.000000    7.895800\n",
      "50%    1100.500000    3.000000   27.000000    0.000000    0.000000   14.454200\n",
      "75%    1204.750000    3.000000   39.000000    1.000000    0.000000   31.500000\n",
      "max    1309.000000    3.000000   76.000000    8.000000    9.000000  512.329200\n",
      "(891, 12)\n",
      "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
      "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
      "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
      "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
      "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
      "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
      "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
      "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
      "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
      "\n",
      "            Parch        Fare  \n",
      "count  891.000000  891.000000  \n",
      "mean     0.381594   32.204208  \n",
      "std      0.806057   49.693429  \n",
      "min      0.000000    0.000000  \n",
      "25%      0.000000    7.910400  \n",
      "50%      0.000000   14.454200  \n",
      "75%      0.000000   31.000000  \n",
      "max      6.000000  512.329200  \n",
      "(891, 9)\n",
      "0      3\n",
      "1      4\n",
      "2      5\n",
      "3      4\n",
      "4      3\n",
      "      ..\n",
      "886    4\n",
      "887    5\n",
      "888    5\n",
      "889    3\n",
      "890    3\n",
      "Name: Name, Length: 891, dtype: int64\n",
      "(891, 12)\n",
      "(418, 12)\n",
      "[[3 3 22.0 ... 0 0 1]\n",
      " [1 4 38.0 ... 1 0 0]\n",
      " [3 5 26.0 ... 0 0 1]\n",
      " ...\n",
      " [3 5 27.0 ... 0 0 1]\n",
      " [1 3 26.0 ... 1 0 0]\n",
      " [3 3 32.0 ... 0 1 0]]\n",
      "Best parameters are: {'max_depth': 32, 'n_estimators': 50}\n",
      "\n",
      "\n",
      "0.793 + or -0.033 for the {'max_depth': 2, 'n_estimators': 5}\n",
      "0.798 + or -0.033 for the {'max_depth': 2, 'n_estimators': 10}\n",
      "0.793 + or -0.029 for the {'max_depth': 2, 'n_estimators': 50}\n",
      "0.791 + or -0.035 for the {'max_depth': 2, 'n_estimators': 100}\n",
      "0.79 + or -0.033 for the {'max_depth': 2, 'n_estimators': 250}\n",
      "0.823 + or -0.028 for the {'max_depth': 4, 'n_estimators': 5}\n",
      "0.824 + or -0.043 for the {'max_depth': 4, 'n_estimators': 10}\n",
      "0.823 + or -0.037 for the {'max_depth': 4, 'n_estimators': 50}\n",
      "0.827 + or -0.035 for the {'max_depth': 4, 'n_estimators': 100}\n",
      "0.826 + or -0.031 for the {'max_depth': 4, 'n_estimators': 250}\n",
      "0.819 + or -0.048 for the {'max_depth': 8, 'n_estimators': 5}\n",
      "0.825 + or -0.058 for the {'max_depth': 8, 'n_estimators': 10}\n",
      "0.834 + or -0.049 for the {'max_depth': 8, 'n_estimators': 50}\n",
      "0.838 + or -0.053 for the {'max_depth': 8, 'n_estimators': 100}\n",
      "0.84 + or -0.055 for the {'max_depth': 8, 'n_estimators': 250}\n",
      "0.815 + or -0.04 for the {'max_depth': 16, 'n_estimators': 5}\n",
      "0.827 + or -0.041 for the {'max_depth': 16, 'n_estimators': 10}\n",
      "0.832 + or -0.045 for the {'max_depth': 16, 'n_estimators': 50}\n",
      "0.84 + or -0.047 for the {'max_depth': 16, 'n_estimators': 100}\n",
      "0.841 + or -0.049 for the {'max_depth': 16, 'n_estimators': 250}\n",
      "0.802 + or -0.036 for the {'max_depth': 32, 'n_estimators': 5}\n",
      "0.833 + or -0.044 for the {'max_depth': 32, 'n_estimators': 10}\n",
      "0.843 + or -0.04 for the {'max_depth': 32, 'n_estimators': 50}\n",
      "0.841 + or -0.042 for the {'max_depth': 32, 'n_estimators': 100}\n",
      "0.837 + or -0.048 for the {'max_depth': 32, 'n_estimators': 250}\n",
      "0.805 + or -0.05 for the {'max_depth': None, 'n_estimators': 5}\n",
      "0.833 + or -0.045 for the {'max_depth': None, 'n_estimators': 10}\n",
      "0.838 + or -0.045 for the {'max_depth': None, 'n_estimators': 50}\n",
      "0.837 + or -0.051 for the {'max_depth': None, 'n_estimators': 100}\n",
      "0.838 + or -0.048 for the {'max_depth': None, 'n_estimators': 250}\n",
      "Your submission was successfully saved!\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import os\n",
    "from xgboost import XGBClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "import csv \n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "np.random.seed(31415)\n",
    "test_file = pd.read_csv(\"/kaggle/input/titanic/test.csv\")\n",
    "print(test_file.shape) #(418,11)\n",
    "print(test_file.describe())\n",
    "\n",
    "train_file = pd.read_csv(\"/kaggle/input/titanic/train.csv\")\n",
    "print(train_file.shape) #(891,12)\n",
    "print(train_file.describe())\n",
    "\n",
    "'''\n",
    "null_test = train_file['Sex'].isnull().sum()\n",
    "print(\"sesso null nel test: \", null_test)\n",
    "null_test = train_file['SibSp'].isnull().sum()\n",
    "print(\"sib null nel test: \", null_test)\n",
    "null_test = train_file['Fare'].isnull().sum()\n",
    "print(\"fare null nel test: \", null_test)\n",
    "null_test = train_file['Name'].isnull().sum()\n",
    "print(\"nome null nel test: \", null_test)\n",
    "null_test = train_file['Parch'].isnull().sum()\n",
    "print(\"parch null nel test: \", null_test)\n",
    "'''\n",
    "samples = train_file[['Pclass', 'Name','Sex', 'Age', 'SibSp', 'Fare', 'Ticket', 'Parch','Embarked']] #excluding cabin and passID, many nans\n",
    "X_test = test_file[['Pclass', 'Name','Sex', 'Age', 'SibSp', 'Fare', 'Ticket','Parch', 'Embarked']]\n",
    "print(samples.shape)\n",
    "\n",
    "#Preparing data\n",
    "\n",
    "samples[\"Age\"].fillna(\n",
    "    samples.groupby([\"Sex\"])[\"Age\"].transform(\n",
    "        lambda x: x.median()\n",
    "    ), inplace=True)\n",
    "\n",
    "samples[\"Fare\"].fillna(\n",
    "    samples.groupby([\"Sex\"])[\"Fare\"].transform(\n",
    "        lambda x: x.mean()\n",
    "    ), inplace=True)\n",
    "\n",
    "samples[\"Embarked\"].fillna(\"S\", inplace=True)\n",
    "\n",
    "X_test[\"Age\"].fillna(\n",
    "    X_test.groupby([\"Sex\"])[\"Age\"].transform(\n",
    "        lambda x: x.mean()\n",
    "    ), inplace=True)\n",
    "\n",
    "X_test[\"Fare\"].fillna(\n",
    "    X_test.groupby([\"Sex\"])[\"Fare\"].transform(\n",
    "        lambda x: x.mean()\n",
    "    ), inplace=True)\n",
    "\n",
    "\n",
    "count = 0\n",
    "for idx in samples['Name']: #turn name into title\n",
    "    idx = idx.split(\",\")[1].split(\".\")[0]\n",
    "    samples.iloc[count,1] = idx\n",
    "    count=count+1\n",
    "\n",
    "count = 0\n",
    "for idx in X_test['Name']: #turn name into title, more meaningful\n",
    "    idx = idx.split(\",\")[1].split(\".\")[0]\n",
    "    X_test.iloc[count,1] = idx\n",
    "    count=count+1\n",
    "\n",
    "def substitute_with_length(string):\n",
    "    if string != '':\n",
    "        return len(string)\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "samples['Name'] = samples['Name'].apply(lambda x: substitute_with_length(x))\n",
    "X_test['Name'] = X_test['Name'].apply(lambda x: substitute_with_length(x))\n",
    "print(samples['Name'])\n",
    "\n",
    "X_test[\"Name\"].fillna(\n",
    "    X_test.groupby([\"Sex\"])[\"Name\"].transform(\n",
    "        lambda x: x.mean()\n",
    "    ), inplace=True)\n",
    "\n",
    "samples[\"Name\"].fillna(\n",
    "    samples.groupby([\"Sex\"])[\"Name\"].transform(\n",
    "        lambda x: x.mean()\n",
    "    ), inplace=True)\n",
    "\n",
    "\n",
    "def remove_non_numeric(string):\n",
    "    result = 0\n",
    "    if (len(string)>0):\n",
    "        result = re.sub('[^0-9]', '',string)\n",
    "    if (result==''):\n",
    "        result = 0\n",
    "    return result\n",
    "\n",
    "# Apply the function to each row of the column\n",
    "samples['Ticket'] = samples['Ticket'].apply(lambda x: remove_non_numeric(x))\n",
    "X_test['Ticket'] = X_test['Ticket'].apply(lambda x: remove_non_numeric(x))\n",
    "\n",
    "samples = pd.get_dummies(samples, prefix=['Sex', 'Embarked'],\n",
    "                         columns=['Sex', 'Embarked']) #one-hot encoding\n",
    "print(samples.shape)\n",
    "samples_np = np.array(samples)\n",
    "\n",
    "X_test = pd.get_dummies(X_test, prefix=['Sex', 'Embarked'],\n",
    "                         columns=['Sex', 'Embarked']) #one-hot encoding\n",
    "print(X_test.shape)\n",
    "X_test = np.array(X_test)\n",
    "\n",
    "labels = train_file[ 'Survived']\n",
    "labels = np.array(labels)\n",
    "\n",
    "#random forest classifier model\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "parameters = {\n",
    "    \"n_estimators\":[5,10,50,100,250],\n",
    "    \"max_depth\":[2,4,8,16,32,None]\n",
    "}\n",
    "\n",
    "print(samples_np)\n",
    "#grid search of best parameters and kfold cross validation (k=10)\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "cv = GridSearchCV(clf,parameters,cv=10)\n",
    "cv.fit(samples_np,labels)\n",
    "\n",
    "\n",
    "def display(results):\n",
    "    print(f'Best parameters are: {results.best_params_}')\n",
    "    print(\"\\n\")\n",
    "    mean_score = results.cv_results_['mean_test_score']\n",
    "    std_score = results.cv_results_['std_test_score']\n",
    "    params = results.cv_results_['params']\n",
    "    for mean,std,params in zip(mean_score,std_score,params):\n",
    "        print(f'{round(mean,3)} + or -{round(std,3)} for the {params}')\n",
    "        \n",
    "display(cv)\n",
    "\n",
    "best_RF_model = RandomForestClassifier(n_estimators = 250)\n",
    "best_RF_model.fit(samples_np,labels)\n",
    "predictions = best_RF_model.predict(X_test)\n",
    "\n",
    "output = pd.DataFrame({'PassengerId': test_file.PassengerId, 'Survived': predictions})\n",
    "output.to_csv('submission.csv', index=False)\n",
    "print(\"Your submission was successfully saved!\")\n",
    "        \n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 26502,
     "sourceId": 3136,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30497,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 89.922037,
   "end_time": "2024-11-06T14:16:12.325646",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-11-06T14:14:42.403609",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
